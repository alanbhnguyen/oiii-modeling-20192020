{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRecreate Woo et al paper (almost) exactly\\n\\nAuthor: Alan Nguyen\\n\\n10-07-2020\\n\\nfits\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Recreate Woo et al paper (almost) exactly\n",
    "\n",
    "Author: Alan Nguyen\n",
    "\n",
    "10-07-2020\n",
    "\n",
    "fits\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table, Column\n",
    "from scipy.optimize import curve_fit, leastsq\n",
    "from scipy.stats import spearmanr\n",
    "from astropy.cosmology import WMAP9 as cosmo\n",
    "from astropy import units as u\n",
    "import os\n",
    "import math as m\n",
    "from astropy import constants as const\n",
    "import time\n",
    "from BOSS_func_v9 import *\n",
    "from general_functions_v1 import *\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdul = fits.open('recreate_woo/gal_info_zbin4.fits')\n",
    "\n",
    "zbin4_data = hdul[1].data\n",
    "\n",
    "hdul.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete: 2/315 darn\n",
      " darn\n",
      "Complete: 4/315 darn\n",
      "Complete: 6/315 darn\n",
      "Complete: 31/315 darn\n",
      "Complete: 44/315 darn\n",
      "Complete: 58/315 darn\n",
      "Complete: 79/315 darn\n",
      "Complete: 162/315 darn\n",
      "Complete: 262/315 darn\n",
      "Complete: 305/315"
     ]
    }
   ],
   "source": [
    "specs ={}\n",
    "count = 0\n",
    "\n",
    "for row in zbin4_data:\n",
    "    \n",
    "    try:\n",
    "        ######################################### set up file directories\n",
    "\n",
    "        PLATE = '{:04}'.format(row['PLATEID'])\n",
    "        MJD   = str(row['MJD'])\n",
    "        FIBER = '{:03}'.format(row['FIBERID'])\n",
    "        key_list = ['spSpec',MJD, PLATE, FIBER]\n",
    "        key = '-'.join(key_list)\n",
    "        filename = key + '.fit'\n",
    "        folder = 'woo_zbin4_specs'\n",
    "\n",
    "        directory = os.path.join(folder, filename)\n",
    "\n",
    "        #########################################\n",
    "\n",
    "        z = row['Z']\n",
    "        k = 1 + z\n",
    "\n",
    "        #########################################\n",
    "\n",
    "        hdul = fits.open(directory) #using above directory open fits for the specific spectra\n",
    "\n",
    "        header = hdul[0].header\n",
    "        data   = hdul[0].data\n",
    "\n",
    "        hdul.close()\n",
    "\n",
    "        #########################################\n",
    "\n",
    "        fluxden = data[0]\n",
    "\n",
    "        COEFF0 = header['COEFF0']\n",
    "        COEFF1 = header['COEFF1']\n",
    "\n",
    "        wave = np.zeros(len(fluxden))\n",
    "\n",
    "        for i in range(len(wave)):\n",
    "            wave[i] = 10 ** (COEFF0 + COEFF1 * i)\n",
    "\n",
    "        #########################################\n",
    "\n",
    "        error = data[2]\n",
    "\n",
    "        #########################################\n",
    "\n",
    "        tempdat = [] #temporary list to hold each dataset before adding it to the dictionary\n",
    "\n",
    "        #list indices to the right, called with spec-XXXX-XXXXX-XXXX, PLATE-MJD-FIBERID\n",
    "        tempdat.append(wave)    #0 \n",
    "        tempdat.append(fluxden) #1\n",
    "        tempdat.append(k)       #2\n",
    "        tempdat.append(error)   #3\n",
    "\n",
    "        specs.update({key:tempdat})\n",
    "\n",
    "        ###############################\n",
    "        ###############################\n",
    "\n",
    "        count += 1\n",
    "        print(\"\\r\" + \"Complete: {}/{}\".format(count,len(zbin4_data)), end = \"\") #progress bar to keep track of progress\n",
    "    except:\n",
    "        print(' darn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Complete: 1/305\r",
      "Complete: 2/305\r",
      "Complete: 3/305\r",
      "Complete: 4/305\r",
      "Complete: 5/305\r",
      "Complete: 6/305\r",
      "Complete: 7/305\r",
      "Complete: 8/305\r",
      "Complete: 9/305\r",
      "Complete: 10/305\r",
      "Complete: 11/305\r",
      "Complete: 12/305\r",
      "Complete: 13/305\r",
      "Complete: 14/305\r",
      "Complete: 15/305\r",
      "Complete: 16/305\r",
      "Complete: 17/305\r",
      "Complete: 18/305\r",
      "Complete: 19/305\r",
      "Complete: 20/305\r",
      "Complete: 21/305\r",
      "Complete: 22/305\r",
      "Complete: 23/305\r",
      "Complete: 24/305\r",
      "Complete: 25/305\r",
      "Complete: 26/305\r",
      "Complete: 27/305\r",
      "Complete: 28/305\r",
      "Complete: 29/305\r",
      "Complete: 30/305\r",
      "Complete: 31/305\r",
      "Complete: 32/305\r",
      "Complete: 33/305\r",
      "Complete: 34/305\r",
      "Complete: 35/305\r",
      "Complete: 36/305\r",
      "Complete: 37/305\r",
      "Complete: 38/305\r",
      "Complete: 39/305\r",
      "Complete: 40/305\r",
      "Complete: 41/305\r",
      "Complete: 42/305\r",
      "Complete: 43/305\r",
      "Complete: 44/305\r",
      "Complete: 45/305\r",
      "Complete: 46/305\r",
      "Complete: 47/305\r",
      "Complete: 48/305\r",
      "Complete: 49/305\r",
      "Complete: 50/305\r",
      "Complete: 51/305\r",
      "Complete: 52/305\r",
      "Complete: 53/305\r",
      "Complete: 54/305\r",
      "Complete: 55/305\r",
      "Complete: 56/305\r",
      "Complete: 57/305\r",
      "Complete: 58/305\r",
      "Complete: 59/305\r",
      "Complete: 60/305\r",
      "Complete: 61/305\r",
      "Complete: 62/305\r",
      "Complete: 63/305\r",
      "Complete: 64/305\r",
      "Complete: 65/305\r",
      "Complete: 66/305\r",
      "Complete: 67/305\r",
      "Complete: 68/305\r",
      "Complete: 69/305\r",
      "Complete: 70/305\r",
      "Complete: 71/305\r",
      "Complete: 72/305\r",
      "Complete: 73/305\r",
      "Complete: 74/305\r",
      "Complete: 75/305\r",
      "Complete: 76/305\r",
      "Complete: 77/305\r",
      "Complete: 78/305\r",
      "Complete: 79/305\r",
      "Complete: 80/305\r",
      "Complete: 81/305\r",
      "Complete: 82/305\r",
      "Complete: 83/305\r",
      "Complete: 84/305\r",
      "Complete: 85/305\r",
      "Complete: 86/305\r",
      "Complete: 87/305\r",
      "Complete: 88/305\r",
      "Complete: 89/305\r",
      "Complete: 90/305\r",
      "Complete: 91/305\r",
      "Complete: 92/305\r",
      "Complete: 93/305\r",
      "Complete: 94/305\r",
      "Complete: 95/305\r",
      "Complete: 96/305\r",
      "Complete: 97/305\r",
      "Complete: 98/305\r",
      "Complete: 99/305\r",
      "Complete: 100/305\r",
      "Complete: 101/305\r",
      "Complete: 102/305\r",
      "Complete: 103/305\r",
      "Complete: 104/305\r",
      "Complete: 105/305\r",
      "Complete: 106/305\r",
      "Complete: 107/305\r",
      "Complete: 108/305\r",
      "Complete: 109/305\r",
      "Complete: 110/305\r",
      "Complete: 111/305\r",
      "Complete: 112/305\r",
      "Complete: 113/305\r",
      "Complete: 114/305\r",
      "Complete: 115/305\r",
      "Complete: 116/305\r",
      "Complete: 117/305\r",
      "Complete: 118/305\r",
      "Complete: 119/305\r",
      "Complete: 120/305\r",
      "Complete: 121/305\r",
      "Complete: 122/305\r",
      "Complete: 123/305\r",
      "Complete: 124/305\r",
      "Complete: 125/305\r",
      "Complete: 126/305\r",
      "Complete: 127/305\r",
      "Complete: 128/305\r",
      "Complete: 129/305\r",
      "Complete: 130/305\r",
      "Complete: 131/305\r",
      "Complete: 132/305\r",
      "Complete: 133/305\r",
      "Complete: 134/305\r",
      "Complete: 135/305\r",
      "Complete: 136/305\r",
      "Complete: 137/305\r",
      "Complete: 138/305\r",
      "Complete: 139/305\r",
      "Complete: 140/305\r",
      "Complete: 141/305\r",
      "Complete: 142/305\r",
      "Complete: 143/305\r",
      "Complete: 144/305\r",
      "Complete: 145/305\r",
      "Complete: 146/305\r",
      "Complete: 147/305\r",
      "Complete: 148/305\r",
      "Complete: 149/305\r",
      "Complete: 150/305\r",
      "Complete: 151/305\r",
      "Complete: 152/305\r",
      "Complete: 153/305\r",
      "Complete: 154/305\r",
      "Complete: 155/305\r",
      "Complete: 156/305\r",
      "Complete: 157/305\r",
      "Complete: 158/305\r",
      "Complete: 159/305\r",
      "Complete: 160/305\r",
      "Complete: 161/305\r",
      "Complete: 162/305\r",
      "Complete: 163/305\r",
      "Complete: 164/305\r",
      "Complete: 165/305\r",
      "Complete: 166/305\r",
      "Complete: 167/305\r",
      "Complete: 168/305\r",
      "Complete: 169/305\r",
      "Complete: 170/305\r",
      "Complete: 171/305\r",
      "Complete: 172/305\r",
      "Complete: 173/305\r",
      "Complete: 174/305\r",
      "Complete: 175/305\r",
      "Complete: 176/305\r",
      "Complete: 177/305\r",
      "Complete: 178/305\r",
      "Complete: 179/305\r",
      "Complete: 180/305\r",
      "Complete: 181/305\r",
      "Complete: 182/305\r",
      "Complete: 183/305\r",
      "Complete: 184/305\r",
      "Complete: 185/305\r",
      "Complete: 186/305\r",
      "Complete: 187/305\r",
      "Complete: 188/305\r",
      "Complete: 189/305\r",
      "Complete: 190/305\r",
      "Complete: 191/305\r",
      "Complete: 192/305\r",
      "Complete: 193/305\r",
      "Complete: 194/305\r",
      "Complete: 195/305\r",
      "Complete: 196/305\r",
      "Complete: 197/305\r",
      "Complete: 198/305\r",
      "Complete: 199/305\r",
      "Complete: 200/305\r",
      "Complete: 201/305\r",
      "Complete: 202/305\r",
      "Complete: 203/305\r",
      "Complete: 204/305\r",
      "Complete: 205/305\r",
      "Complete: 206/305\r",
      "Complete: 207/305\r",
      "Complete: 208/305\r",
      "Complete: 209/305\r",
      "Complete: 210/305\r",
      "Complete: 211/305\r",
      "Complete: 212/305\r",
      "Complete: 213/305\r",
      "Complete: 214/305\r",
      "Complete: 215/305\r",
      "Complete: 216/305\r",
      "Complete: 217/305\r",
      "Complete: 218/305\r",
      "Complete: 219/305\r",
      "Complete: 220/305\r",
      "Complete: 221/305\r",
      "Complete: 222/305\r",
      "Complete: 223/305\r",
      "Complete: 224/305\r",
      "Complete: 225/305\r",
      "Complete: 226/305\r",
      "Complete: 227/305\r",
      "Complete: 228/305\r",
      "Complete: 229/305\r",
      "Complete: 230/305\r",
      "Complete: 231/305\r",
      "Complete: 232/305\r",
      "Complete: 233/305\r",
      "Complete: 234/305\r",
      "Complete: 235/305\r",
      "Complete: 236/305\r",
      "Complete: 237/305\r",
      "Complete: 238/305\r",
      "Complete: 239/305\r",
      "Complete: 240/305\r",
      "Complete: 241/305\r",
      "Complete: 242/305\r",
      "Complete: 243/305\r",
      "Complete: 244/305\r",
      "Complete: 245/305\r",
      "Complete: 246/305\r",
      "Complete: 247/305\r",
      "Complete: 248/305\r",
      "Complete: 249/305\r",
      "Complete: 250/305\r",
      "Complete: 251/305\r",
      "Complete: 252/305\r",
      "Complete: 253/305\r",
      "Complete: 254/305\r",
      "Complete: 255/305\r",
      "Complete: 256/305\r",
      "Complete: 257/305\r",
      "Complete: 258/305\r",
      "Complete: 259/305\r",
      "Complete: 260/305\r",
      "Complete: 261/305\r",
      "Complete: 262/305\r",
      "Complete: 263/305\r",
      "Complete: 264/305\r",
      "Complete: 265/305\r",
      "Complete: 266/305\r",
      "Complete: 267/305\r",
      "Complete: 268/305\r",
      "Complete: 269/305\r",
      "Complete: 270/305\r",
      "Complete: 271/305\r",
      "Complete: 272/305\r",
      "Complete: 273/305\r",
      "Complete: 274/305\r",
      "Complete: 275/305\r",
      "Complete: 276/305\r",
      "Complete: 277/305\r",
      "Complete: 278/305\r",
      "Complete: 279/305\r",
      "Complete: 280/305\r",
      "Complete: 281/305\r",
      "Complete: 282/305\r",
      "Complete: 283/305\r",
      "Complete: 284/305\r",
      "Complete: 285/305\r",
      "Complete: 286/305\r",
      "Complete: 287/305\r",
      "Complete: 288/305\r",
      "Complete: 289/305\r",
      "Complete: 290/305\r",
      "Complete: 291/305\r",
      "Complete: 292/305\r",
      "Complete: 293/305\r",
      "Complete: 294/305\r",
      "Complete: 295/305\r",
      "Complete: 296/305\r",
      "Complete: 297/305\r",
      "Complete: 298/305\r",
      "Complete: 299/305\r",
      "Complete: 300/305\r",
      "Complete: 301/305\r",
      "Complete: 302/305\r",
      "Complete: 303/305\r",
      "Complete: 304/305\r",
      "Complete: 305/305"
     ]
    }
   ],
   "source": [
    "#\n",
    "#bring down the size of the dictionary to create a smaller working dictionary, trimmed just for the [OIII]5007 line\n",
    "#\n",
    "\n",
    "trimmed_specs = {}\n",
    "\n",
    "count = 0 #for a loading bar lmao\n",
    "\n",
    "bad_specs = []\n",
    "\n",
    "for key in specs: #for every spectrum generated in previous block\n",
    "    wave = specs[key][0] #extract wavelength array\n",
    "    fluxden = specs[key][1] #extract flux density array\n",
    "    k = specs[key][2] #z + 1, to account for redshift during the trimming\n",
    "    error = specs[key][3] #extract flux density error array\n",
    "    \n",
    "    ###############################\n",
    "    ###############################\n",
    "\n",
    "    OIII_select = (wave > 4980*k) & (wave < 5030*k) #create parameter to trim the data for the [OIII]5007 line\n",
    "\n",
    "    OIII_wave = wave[OIII_select] #select for [OIII]5007\n",
    "    OIII_fluxden = fluxden[OIII_select] #select for [OIII]5007\n",
    "    OIII_error = error[OIII_select] #select for [OIII]5007\n",
    "    \n",
    "    ###############################\n",
    "    ###############################\n",
    "    \n",
    "    inf_indices = np.where(OIII_error == np.inf) #take indices where error is infinity for some reason?\n",
    "    \n",
    "    mean_error = np.mean(OIII_error[OIII_error != np.inf]) #take the mean error from the [OIII]5007 slice\n",
    "    \n",
    "    for i in inf_indices[0]: #replace all the infinity indices with the mean error\n",
    "        OIII_error[i] = mean_error\n",
    "    \n",
    "    ###############################\n",
    "    ###############################\n",
    "    \n",
    "    OIII_fluxden_scale = np.max(OIII_fluxden) #take the scale factor as the maximum flux density in this region\n",
    "    \n",
    "    OIII_norm_fluxden = OIII_fluxden / OIII_fluxden_scale #normalize so the peak is at one\n",
    "    OIII_norm_error = OIII_error / OIII_fluxden_scale #scale the error to preserve relationship with flux density\n",
    "    \n",
    "    ###############################\n",
    "    ###############################\n",
    "    \n",
    "    tempdat = [] #temporary list to hold each dataset before adding it to the dictionary\n",
    "    \n",
    "    #list indices to the right, called with spec-XXXX-XXXXX-XXXX, PLATE-MJD-FIBERID\n",
    "    tempdat.append(OIII_wave)          #0 wavelength\n",
    "    tempdat.append(OIII_norm_fluxden)  #1 normalized flux density\n",
    "    tempdat.append(k)                  #2 k = z + 1\n",
    "    tempdat.append(OIII_norm_error)    #3 normalized flux density error\n",
    "    tempdat.append(OIII_fluxden_scale) #4 maximum flux density used to scale normalized flux density\n",
    "    \n",
    "    trimmed_specs.update({key:tempdat}) #update the trimmed dictionary with a smaller dataset\n",
    "    \n",
    "    ###############################\n",
    "    ###############################\n",
    "    \n",
    "    if OIII_fluxden_scale == 0: #add to list of \"flat\" spectra\n",
    "        bad_specs.append(key)\n",
    "    \n",
    "    ###############################\n",
    "    ###############################\n",
    "    \n",
    "    count += 1\n",
    "    print(\"\\r\" + \"Complete: {}/{}\".format(count,len(specs)), end = \"\") #progress bar to keep track of progress\n",
    "    \n",
    "    ###############################\n",
    "    ###############################\n",
    "    \n",
    "for s in bad_specs: #remove bad spectra from the trimmed dictionary\n",
    "    trimmed_specs.pop(key, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "AN_specs = {}\n",
    "\n",
    "for key in trimmed_specs:\n",
    "    \n",
    "    OIII_wave    = trimmed_specs[key][0] #array with wavelength values for the current spectrum in angstrom\n",
    "    OIII_fluxden = trimmed_specs[key][1] #array with corresponding flux density values\n",
    "    k            = trimmed_specs[key][2]\n",
    "    OIII_error   = trimmed_specs[key][3] \n",
    "    \n",
    "    ye = np.where(OIII_wave == 5007*k)\n",
    "    distance_to_center = np.zeros(len(OIII_wave))\n",
    "    \n",
    "    for i in range(len(OIII_wave)):\n",
    "        distance_to_center[i] = np.abs(OIII_wave[i] - 5007*k)\n",
    "    \n",
    "    center_index = np.where(distance_to_center == np.min(distance_to_center))[0][0]\n",
    "    center_flux  = OIII_fluxden[center_index]\n",
    "    center_error = OIII_error[center_index]\n",
    "    \n",
    "    AN = center_flux / center_error\n",
    "\n",
    "    AN_specs.update({key:AN})\n",
    "\n",
    "for key in AN_specs:\n",
    "    if AN_specs[key] < 5:\n",
    "        trimmed_specs.pop(key, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Complete: 1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\minpack.py:447: RuntimeWarning: Number of calls to function has reached maxfev = 100000.\n",
      "  warnings.warn(errors[info][0], RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete: 56"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:94: RuntimeWarning: divide by zero encountered in true_divide\n",
      "C:\\Users\\ANguyen\\MyWorks\\BOSS_func_v9.py:60: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return (fit - fluxden) / error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete: 305 \n",
      "Runtime: 5226.046875s\n"
     ]
    }
   ],
   "source": [
    "############################### here is the initial run with all specs\n",
    "###############################\n",
    "\n",
    "\n",
    "preset_parameters = {} #called with spec-XXXX-XXXXX-XXXX, PLATE-MJD-FIBERID, fit\n",
    "TRIALS = 100 #set number of trials for the Monte-Carlo error\n",
    "MC_flags = np.zeros((TRIALS, len(trimmed_specs)))\n",
    "count = 0\n",
    "final_results = {}\n",
    "start_time = time.process_time()\n",
    "negative_amp_fits = []\n",
    "\n",
    "for key in trimmed_specs: #loop and use the fit on all the trimmed specs\n",
    "    \n",
    "    used_preset = False #by default use the generic initial conditions\n",
    "\n",
    "    OIII_wave    = trimmed_specs[key][0] #array with wavelength values for the current spectrum in angstrom\n",
    "    OIII_fluxden = trimmed_specs[key][1] #array with corresponding flux density values\n",
    "    k            = trimmed_specs[key][2] #corresponding z + 1 value\n",
    "    OIII_error   = trimmed_specs[key][3] #array with corresponding flux density error values\n",
    "    \n",
    "    ###############################\n",
    "    ###############################\n",
    "    \n",
    "    specific_presets = {} #prepare a dictionary with velocity means corrected for the current spectrum's k value\n",
    "\n",
    "    for p in preset_parameters: #for every key in the preset parameters\n",
    "        \n",
    "    ###############################\n",
    "    ###############################\n",
    "        \n",
    "        k_corrected_parameters = preset_parameters[p][0] #take the parameters first \n",
    "        \n",
    "    ###############################\n",
    "    \n",
    "#     Using z = v / c\n",
    "    \n",
    "#     z1 / v1 = c = z2 / v2\n",
    "    \n",
    "#     v2 = (z2 / z1) * v1\n",
    "    \n",
    "#     z2 = k_spectrum - 1\n",
    "\n",
    "#     z1 = k_fit - 1\n",
    "    \n",
    "    ###############################\n",
    "        \n",
    "        k_corrected_parameters[1] = ((k - 1)/(preset_parameters[p][1] - 1)) * k_corrected_parameters[1]\n",
    "        k_corrected_parameters[4] = ((k - 1)/(preset_parameters[p][1] - 1)) * k_corrected_parameters[4]\n",
    "        \n",
    "    ###############################\n",
    "#   \n",
    "    \n",
    "#     Sometimes get a problem with the above\n",
    "    \n",
    "#   \n",
    "    ###############################\n",
    "        \n",
    "        #if the angstrom value of the mean is not within the wavelength range, then bring it back into the range for both means\n",
    "        if to_angstrom_OIII(k_corrected_parameters[1]) >= OIII_wave[-1] or to_angstrom_OIII(k_corrected_parameters[1]) <= OIII_wave[0]:\n",
    "            k_corrected_parameters[1] = (k - 1) * 300000\n",
    "         \n",
    "        if to_angstrom_OIII(k_corrected_parameters[4]) >= OIII_wave[-1] or to_angstrom_OIII(k_corrected_parameters[4]) <= OIII_wave[0]:\n",
    "            k_corrected_parameters[4] = (k - 1) * 300000\n",
    "            \n",
    "        #if it turns out that both are not in the range, make generic velocity means and keep widths and amplitudes\n",
    "        if k_corrected_parameters[1] == k_corrected_parameters[4]:\n",
    "            k_corrected_parameters[1] = to_vel_OIII(5007*k)\n",
    "            k_corrected_parameters[4] = identify_wing(OIII_wave, OIII_fluxden, k)\n",
    "        \n",
    "        specific_presets.update({p:k_corrected_parameters}) #update the specific presets dictionary with the k corrected velocity means\n",
    "    \n",
    "    if len(preset_parameters) == 0: #this is for the first iteration\n",
    "        similarity_table = np.zeros(shape = (1, 9)) #make a single row with [0] the rcsq, [1:8] parameters, filled with zeros\n",
    "        similarity_table[0][0] = np.inf #set the rcsq value to infinity to force generic parameters because there are no presets to try\n",
    "        \n",
    "    else:\n",
    "        similarity_table = np.zeros(shape = (len(preset_parameters), 9)) #create empty array to store rcsq and parameters used to generate them\n",
    "    \n",
    "    ###############################\n",
    "    ###############################\n",
    "    \n",
    "    #generate initial parameters\n",
    "    \n",
    "    ###############################\n",
    "    ###############################\n",
    "    \n",
    "    double_gaussian_parameters = double_gauss_params(OIII_wave, OIII_fluxden, k) #generate generic parameters\n",
    "    \n",
    "    parameters_counter = 0 #used to loop down the similarity table\n",
    "    \n",
    "    for p in specific_presets: #try to see if can get better starting parameters from the previously done spectra\n",
    "        \n",
    "        similarity1 = np.sum(((OIII_fluxden - double_gaussian_lincont(OIII_wave, specific_presets[p])) / OIII_error) ** 2) #take csq between current data in iteration and fits from preset\n",
    "        similarity2 = similarity1 / len(OIII_fluxden) #divide by length for reduced chi squared\n",
    "                                        \n",
    "        similarity_table[parameters_counter][0] = similarity2 #parameters_counter gives row, first entry is the similiarity2, rcsq for the current parameters being tested\n",
    "        similarity_table[parameters_counter][1::] = specific_presets[p] #set the rest of the row to the parameters used to generate the similarity2, rcsq\n",
    "        parameters_counter += 1\n",
    "\n",
    "    best_rcsq = np.min(similarity_table[:,0]) #identify the lowest value in the first column, the best rcsq\n",
    "    \n",
    "    ###############################\n",
    "    ###############################\n",
    "    \n",
    "    initial_conditions = np.zeros(shape = (1, 8)) #make an empty array with enough space to hold the 8 parameters\n",
    "    \n",
    "    ###############################\n",
    "    ###############################\n",
    "    \n",
    "    try: #will almost always use this\n",
    "        if best_rcsq <= 20: #arbitrary guess, seems to give lowest average rcsq\n",
    "\n",
    "            used_preset = True #note that a preset was used, do not update the dictionary with this fit\n",
    "            \n",
    "            initial_conditions = similarity_table[np.where(similarity_table[:,0] == best_rcsq)][0][1::] #find the row corresponding to the lowest rcsq value and set the initial conditions to those parameters\n",
    "\n",
    "        else:\n",
    "            initial_conditions = double_gaussian_parameters #if the best rcsq isn't lower than 40 (again, arbitrary guess) then force the generic parameters\n",
    "    \n",
    "    except: #iterations with a 0 length preset parameters may run into an error, force generic parameters in that case\n",
    "        initial_conditions = double_gaussian_parameters\n",
    "    \n",
    "    ###############################\n",
    "    ###############################\n",
    "\n",
    "    MC_params = np.zeros((TRIALS, 9))\n",
    "    \n",
    "    ###############################\n",
    "    ###############################ERROR IN PARAMETERS\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for r in range(TRIALS): #create a fit for every row of MC_params, number of TRIALS\n",
    "        iter_dat = np.random.normal(OIII_fluxden, OIII_error) #fluctuate the data using the given error\n",
    "        iter_dat = iter_dat.astype('float32') #change data type so it works lol\n",
    "\n",
    "        fit_params = leastsq(double_gaussian_lincont_fit, x0 = initial_conditions, args = (OIII_wave, iter_dat, OIII_error), maxfev = 100000) #fit the iteration data using the same initial parameters\n",
    "        MC_params[r][0:8] = fit_params[0] #set the first 8 columns with the parameters\n",
    "        iter_flag = flag_spec(fit_params, OIII_wave, iter_dat, OIII_error) #flag the iteration fit\n",
    "        MC_params[r][8] = iter_flag #give the 9th column the iteration flag\n",
    "        \n",
    "    for i in range(8): #now loop over the first 8 columns\n",
    "        results.append(np.mean(MC_params[:,i]))\n",
    "        results.append(np.std(MC_params[:,i]))\n",
    "    \n",
    "    final_params = np.array(results)\n",
    "    #0 amplitude1               8 velocity_mean2\n",
    "    #1 amplitude1_error         9 velocity_mean2_error\n",
    "    #2 velocity_mean1          10 velocity_width2\n",
    "    #3 velocity_mean1_error    11 velocity_width2_error\n",
    "    #4 velocity_width1         12 linear_slope\n",
    "    #5 velocity_width1_error   13 linear_slope_error\n",
    "    #6 amplitude2              14 linear_yintercept\n",
    "    #7 amplitude2_error        15 linear_yintercept_error\n",
    "    \n",
    "    MC_flags[:,count] = MC_params[:,8]\n",
    "    \n",
    "#     final_params = np.array([final_params[0::2], 0])\n",
    "#     final_flag = flag_spec(final_params, OIII_wave, OIII_fluxden, OIII_error)\n",
    "    \n",
    "    ###############################\n",
    "    ###############################\n",
    "    \n",
    "    fit_params = leastsq(double_gaussian_lincont_fit, x0 = initial_conditions, args = (OIII_wave, OIII_fluxden, OIII_error), maxfev = 100000) #call the least squares fit using which ever initial conditions were used\n",
    "    \n",
    "    params = fit_params[0] #take only the parameters\n",
    "     \n",
    "#     fit = double_gaussian_lincont(OIII_wave, params) #generate y values for the fit\n",
    "    \n",
    "#     csq = np.sum(((OIII_fluxden - double_gaussian_lincont(OIII_wave, params)) / OIII_error) ** 2) #take csq between current data in iteration and fits from preset\n",
    "#     rcsq = csq / len(OIII_fluxden) #divide by length for reduced chi squared\n",
    "    \n",
    "    ###############################\n",
    "    ###############################\n",
    "    \n",
    "    #Here we check for bad data, mostly negative amplitude\n",
    "    \n",
    "    flag_fit = flag_spec(fit_params, OIII_wave, OIII_fluxden, OIII_error)\n",
    "    \n",
    "    ###############################\n",
    "    ###############################\n",
    "    \n",
    "    if used_preset == False and flag_fit != 0: #if a preset was not used and it was not flagged bad_data, then update a new preset in the dictionary with this fit \n",
    "        preset_parameters.update({key:[params, k]}) #0 fit parameters, 1 k value\n",
    "    \n",
    "    ###############################\n",
    "    ###############################\n",
    "    \n",
    "    if flag_fit == 0:\n",
    "        negative_amp_fits.append([key,count])\n",
    "    \n",
    "    final_error = final_params[1::2]\n",
    "    \n",
    "    final_results_params = np.zeros(16)\n",
    "    final_results_params[0:8]  = params\n",
    "    final_results_params[8:16] = final_error\n",
    "    \n",
    "    final_results.update({key:final_results_params})\n",
    "    \n",
    "    count += 1\n",
    "    print(\"\\r\" + \"Complete: {}\".format(count), end = \"\")\n",
    "    \n",
    "print(\" \")\n",
    "print(\"Runtime: {}s\".format((time.process_time() - start_time)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preset_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in trimmed_specs:\n",
    "    error = trimmed_specs[key][3]\n",
    "    \n",
    "    mean_error = np.mean(error)\n",
    "    \n",
    "    for i in range(len(error)):\n",
    "        if error[i] == 0:\n",
    "            error[i] = mean_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negative_amp_fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete: 43 \n",
      "Runtime: 197.5625s\n"
     ]
    }
   ],
   "source": [
    "############################### here is the second run with the bad fits, now constrained with only positive parameters\n",
    "###############################\n",
    "\n",
    "#all the leastsq fitting lines need to be replaced by bounded curve_fit but only for the negative amps\n",
    "#try using previous presets with bounded curvefit\n",
    "\n",
    "# preset_parameters = {} #called with spec-XXXX-XXXXX-XXXX, PLATE-MJD-FIBERID, fit\n",
    "TRIALS = 100 #set number of trials for the Monte-Carlo error\n",
    "# MC_flags_2 = np.zeros((TRIALS, len(negative_amp_fits)))\n",
    "count = 0\n",
    "# final_results = {}\n",
    "start_time = time.process_time()\n",
    "\n",
    "for _ in negative_amp_fits: #loop and use the fit on all the trimmed specs\n",
    "    \n",
    "    key = _[0]\n",
    "    MC_column = _[1]\n",
    "    \n",
    "    used_preset = False #by default use the generic initial conditions\n",
    "\n",
    "    OIII_wave    = trimmed_specs[key][0] #array with wavelength values for the current spectrum in angstrom\n",
    "    OIII_fluxden = trimmed_specs[key][1] #array with corresponding flux density values\n",
    "    k            = trimmed_specs[key][2] #corresponding z + 1 value\n",
    "    OIII_error   = trimmed_specs[key][3] #array with corresponding flux density error values\n",
    "    \n",
    "    OIII_wave    = np.float64(OIII_wave)\n",
    "    OIII_fluxden = np.float64(OIII_fluxden)\n",
    "    OIII_error   = np.float64(OIII_error)\n",
    "    \n",
    "    ###############################\n",
    "    ###############################\n",
    "    \n",
    "    specific_presets = {} #prepare a dictionary with velocity means corrected for the current spectrum's k value\n",
    "\n",
    "    for p in preset_parameters: #for every key in the preset parameters\n",
    "        \n",
    "    ###############################\n",
    "    ###############################\n",
    "        \n",
    "        k_corrected_parameters = preset_parameters[p][0] #take the parameters first \n",
    "        \n",
    "    ###############################\n",
    "    ###############################\n",
    "        \n",
    "        k_corrected_parameters[1] = ((k - 1)/(preset_parameters[p][1] - 1)) * k_corrected_parameters[1]\n",
    "        k_corrected_parameters[4] = ((k - 1)/(preset_parameters[p][1] - 1)) * k_corrected_parameters[4]\n",
    "        \n",
    "    ###############################\n",
    "#   \n",
    "    \n",
    "#     Sometimes get a problem with the above\n",
    "    \n",
    "#   \n",
    "    ###############################\n",
    "        \n",
    "        #if the angstrom value of the mean is not within the wavelength range, then bring it back into the range for both means\n",
    "        if to_angstrom_OIII(k_corrected_parameters[1]) >= OIII_wave[-1] or to_angstrom_OIII(k_corrected_parameters[1]) <= OIII_wave[0]:\n",
    "            k_corrected_parameters[1] = (k - 1) * 300000\n",
    "         \n",
    "        if to_angstrom_OIII(k_corrected_parameters[4]) >= OIII_wave[-1] or to_angstrom_OIII(k_corrected_parameters[4]) <= OIII_wave[0]:\n",
    "            k_corrected_parameters[4] = (k - 1) * 300000\n",
    "            \n",
    "        #if it turns out that both are not in the range, make generic velocity means and keep widths and amplitudes\n",
    "        if k_corrected_parameters[1] == k_corrected_parameters[4]:\n",
    "            k_corrected_parameters[1] = to_vel_OIII(5007*k)\n",
    "            k_corrected_parameters[4] = identify_wing(OIII_wave, OIII_fluxden, k)\n",
    "        \n",
    "        specific_presets.update({p:k_corrected_parameters}) #update the specific presets dictionary with the k corrected velocity means\n",
    "    \n",
    "    if len(preset_parameters) == 0: #this is for the first iteration\n",
    "        similarity_table = np.zeros(shape = (1, 9)) #make a single row with [0] the rcsq, [1:8] parameters, filled with zeros\n",
    "        similarity_table[0][0] = np.inf #set the rcsq value to infinity to force generic parameters because there are no presets to try\n",
    "        \n",
    "    else:\n",
    "        similarity_table = np.zeros(shape = (len(preset_parameters), 9)) #create empty array to store rcsq and parameters used to generate them\n",
    "    \n",
    "    ###############################\n",
    "    ###############################\n",
    "    \n",
    "    # generate initial parameters\n",
    "    \n",
    "    ###############################\n",
    "    ###############################\n",
    "    \n",
    "    double_gaussian_parameters = double_gauss_params(OIII_wave, OIII_fluxden, k) #generate generic parameters\n",
    "    \n",
    "    parameters_counter = 0 #used to loop down the similarity table\n",
    "    \n",
    "    for p in specific_presets: #try to see if can get better starting parameters from the previously done spectra\n",
    "        \n",
    "        similarity1 = np.sum(((OIII_fluxden - double_gaussian_lincont(OIII_wave, specific_presets[p])) / OIII_error) ** 2) #take csq between current data in iteration and fits from preset\n",
    "        similarity2 = similarity1 / len(OIII_fluxden) #divide by length for reduced chi squared\n",
    "                                        \n",
    "        similarity_table[parameters_counter][0] = similarity2 #parameters_counter gives row, first entry is the similiarity2, rcsq for the current parameters being tested\n",
    "        similarity_table[parameters_counter][1::] = specific_presets[p] #set the rest of the row to the parameters used to generate the similarity2, rcsq\n",
    "        parameters_counter += 1\n",
    "\n",
    "    best_rcsq = np.min(similarity_table[:,0]) #identify the lowest value in the first column, the best rcsq\n",
    "    \n",
    "    ###############################\n",
    "    ###############################\n",
    "    \n",
    "    initial_conditions = np.zeros(shape = (1, 8)) #make an empty array with enough space to hold the 8 parameters\n",
    "    \n",
    "    ###############################\n",
    "    ###############################\n",
    "    \n",
    "    try: #will almost always use this\n",
    "        if best_rcsq <= 20: #arbitrary guess, seems to give lowest average rcsq\n",
    "\n",
    "            used_preset = True #note that a preset was used, do not update the dictionary with this fit\n",
    "            \n",
    "            initial_conditions = similarity_table[np.where(similarity_table[:,0] == best_rcsq)][0][1::] #find the row corresponding to the lowest rcsq value and set the initial conditions to those parameters\n",
    "\n",
    "        else:\n",
    "            initial_conditions = double_gaussian_parameters #if the best rcsq isn't lower than 40 (again, arbitrary guess) then force the generic parameters\n",
    "    \n",
    "    except: #iterations with a 0 length preset parameters may run into an error, force generic parameters in that case\n",
    "        initial_conditions = double_gaussian_parameters\n",
    "    \n",
    "    ###############################\n",
    "    ###############################\n",
    "\n",
    "    MC_params = np.zeros((TRIALS, 9))\n",
    "    \n",
    "    ###############################\n",
    "    ############################### ERROR IN PARAMETERS\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for r in range(TRIALS): #create a fit for every row of MC_params, number of TRIALS\n",
    "        iter_dat = np.random.normal(OIII_fluxden, OIII_error) #fluctuate the data using the given error\n",
    "        iter_dat = np.float64(iter_dat) #change data type so it works lol\n",
    "        try:\n",
    "            popt, pcov = curve_fit(double_gaussian_lincont_curvefit, OIII_wave, iter_dat, initial_conditions, OIII_error, bounds = ((0, -np.inf, -np.inf, 0, -np.inf, -np.inf, -np.inf, -np.inf), (np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, np.inf)), method = 'trf', maxfev = 500000)\n",
    "        except:\n",
    "            popt, pcov = curve_fit(double_gaussian_lincont_curvefit, OIII_wave, iter_dat, double_gaussian_parameters, OIII_error, bounds = ((0, -np.inf, -np.inf, 0, -np.inf, -np.inf, -np.inf, -np.inf), (np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, np.inf)), method = 'trf', maxfev = 500000)\n",
    "        MC_params[r][0:8] = popt #set the first 8 columns with the parameters\n",
    "        iter_flag = flag_spec([popt], OIII_wave, iter_dat, OIII_error) #flag the iteration fit\n",
    "        MC_params[r][8] = iter_flag #give the 9th column the iteration flag\n",
    "        \n",
    "    for i in range(8): #now loop over the first 8 columns\n",
    "        results.append(np.mean(MC_params[:,i]))\n",
    "        results.append(np.std(MC_params[:,i]))\n",
    "    \n",
    "    final_params = np.array(results)    \n",
    "    #0 amplitude1               8 velocity_mean2\n",
    "    #1 amplitude1_error         9 velocity_mean2_error\n",
    "    #2 velocity_mean1          10 velocity_width2\n",
    "    #3 velocity_mean1_error    11 velocity_width2_error\n",
    "    #4 velocity_width1         12 linear_slope\n",
    "    #5 velocity_width1_error   13 linear_slope_error\n",
    "    #6 amplitude2              14 linear_yintercept\n",
    "    #7 amplitude2_error        15 linear_yintercept_error\n",
    "    \n",
    "\n",
    "    MC_flags[:, MC_column] = MC_params[:,8]\n",
    "    \n",
    "#     final_params = np.array([final_params[0::2], 0])\n",
    "#     final_flag = flag_spec(final_params, OIII_wave, OIII_fluxden, OIII_error)\n",
    "    \n",
    "#     print(final_params)\n",
    "\n",
    "    ###########################\n",
    "    ###########################\n",
    "    \n",
    "    try:\n",
    "        popt, pcov = curve_fit(double_gaussian_lincont_curvefit, OIII_wave, iter_dat, initial_conditions, OIII_error, bounds = ((0, -np.inf, -np.inf, 0, -np.inf, -np.inf, -np.inf, -np.inf), (np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, np.inf)), method = 'trf', maxfev = 500000)\n",
    "    except:\n",
    "        popt, pcov = curve_fit(double_gaussian_lincont_curvefit, OIII_wave, iter_dat, double_gaussian_parameters, OIII_error, bounds = ((0, -np.inf, -np.inf, 0, -np.inf, -np.inf, -np.inf, -np.inf), (np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, np.inf)), method = 'trf', maxfev = 500000)\n",
    "    params = popt #take only the parameters\n",
    "     \n",
    "#     fit = double_gaussian_lincont(OIII_wave, params) #generate y values for the fit\n",
    "    \n",
    "#     csq = np.sum(((OIII_fluxden - double_gaussian_lincont(OIII_wave, params)) / OIII_error) ** 2) #take csq between current data in iteration and fits from preset\n",
    "#     rcsq = csq / len(OIII_fluxden) #divide by length for reduced chi squared\n",
    "    \n",
    "    ###############################\n",
    "    ###############################\n",
    "    \n",
    "    #Here we check for bad data, mostly negative amplitude\n",
    "    \n",
    "#     flag_fit = flag_spec(fit_params, OIII_wave, OIII_fluxden, OIII_error)\n",
    "    \n",
    "    #unnecessary as all specs are bad lmao\n",
    "    \n",
    "    ###############################\n",
    "    ###############################\n",
    "    \n",
    "    if used_preset == False: #if a preset was not used and it was not flagged bad_data, then update a new preset in the dictionary with this fit \n",
    "        preset_parameters.update({key:[params, k]}) #0 fit parameters, 1 k value\n",
    "    \n",
    "    ###############################\n",
    "    ###############################\n",
    "    \n",
    "    count += 1\n",
    "    print(\"\\r\" + \"Complete: {}\".format(count), end = \"\")\n",
    "    \n",
    "    final_error = final_params[1::2]\n",
    "    \n",
    "    final_results_params = np.zeros(16)\n",
    "    final_results_params[0:8]  = params\n",
    "    final_results_params[8:16] = final_error\n",
    "\n",
    "    final_results.update({key:final_results_params})\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "print(\" \")\n",
    "print(\"Runtime: {}s\".format((time.process_time() - start_time)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 8, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-d1c8c44623b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrimmed_specs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflag_spec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwave\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfluxden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mparameters_and_flag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\MyWorks\\BOSS_func_v9.py\u001b[0m in \u001b[0;36mflag_spec\u001b[1;34m(fit_parameters, wave, fluxden, error)\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[0mFLAG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m     \u001b[0mcsq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfluxden\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdouble_gaussian_lincont\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwave\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_parameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m     \u001b[0mrcsq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsq\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfluxden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\MyWorks\\BOSS_func_v9.py\u001b[0m in \u001b[0;36mdouble_gaussian_lincont\u001b[1;34m(x, params)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdouble_gaussian_lincont\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0mamp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvel1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvel_sigma1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mamp2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvel2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvel_sigma2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgaussian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mamp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvel1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvel_sigma1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mgaussian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;33m[\u001b[0m\u001b[0mamp2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvel2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvel_sigma2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlinear_continuum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mslope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 8, got 2)"
     ]
    }
   ],
   "source": [
    "############################### add flags to final_results\n",
    "###############################\n",
    "\n",
    "for key in final_results:\n",
    "    parameters = final_results[key]\n",
    "    \n",
    "    wave = trimmed_specs[key][0]\n",
    "    fluxden = trimmed_specs[key][1]\n",
    "    model = final_results[key][0:8]\n",
    "    error = trimmed_specs[key][3]\n",
    "    \n",
    "    flag = flag_spec(np.array([model]), wave, fluxden, error)\n",
    "    \n",
    "    parameters_and_flag = [parameters, flag]\n",
    "    \n",
    "    final_results.update({key:parameters_and_flag})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### here we check for single gaussian preapre to refit with a single gaussian model\n",
    "###############################\n",
    "\n",
    "for key in trimmed_specs:\n",
    "    wave = trimmed_specs[key][0]\n",
    "    fluxden = trimmed_specs[key][1]\n",
    "    model = final_results[key][0][0:8]\n",
    "    error = trimmed_specs[key][3]\n",
    "    \n",
    "    flag = final_results[key][1]\n",
    "    \n",
    "    if flag == 2 or flag == 3:\n",
    "        \n",
    "        component1 = final_results[key][0][0:3]\n",
    "        component2 = final_results[key][0][3:6]\n",
    "\n",
    "        amp_component1 = component1[0]\n",
    "        amp_component2 = component2[0]\n",
    "\n",
    "        if amp_component1 < amp_component2:\n",
    "            min_component = component1\n",
    "        else:\n",
    "            min_component = component2\n",
    "\n",
    "        min_component_plot = gaussian(wave, min_component)\n",
    "\n",
    "        # take the lower of the two amplitudes to compare with the noise level at that index\n",
    "\n",
    "        min_component_amp = np.max(min_component_plot)\n",
    "\n",
    "        amp_component_index = np.where(min_component_plot == min_component_amp)\n",
    "\n",
    "        AN_min_component = min_component_amp / error[amp_component_index]\n",
    "\n",
    "        if (len(AN_min_component) > 1):\n",
    "            flag = 1\n",
    "        elif (AN_min_component < 3):\n",
    "            flag = 1\n",
    "    \n",
    "    final_results_2.update({key:[final_results[key][0], flag]})\n",
    "    \n",
    "#     if flag == 2 or flag == 3:\n",
    "#         plt.plot(wave, min_component_plot)\n",
    "#         plt.plot(wave, error)\n",
    "#         plt.show()\n",
    "#         plt.clf()\n",
    "#         print(AN_min_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_3 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in trimmed_specs:\n",
    "    wave = trimmed_specs[key][0]\n",
    "    fluxden = trimmed_specs[key][1]\n",
    "    error = trimmed_specs[key][3]\n",
    "    \n",
    "    flag = final_results_2[key][1]\n",
    "    \n",
    "    if flag == 2 or flag == 3:\n",
    "        \n",
    "        model = final_results_2[key][0]\n",
    "        \n",
    "        vel_core       = model[2]\n",
    "        vel_core_error = model[10]\n",
    "        \n",
    "        vel_wing       = model[5]\n",
    "        vel_wing_error = model[11]\n",
    "        \n",
    "        vel_outflow = vel_core - vel_wing\n",
    "        \n",
    "        if np.abs(vel_outflow) < np.sqrt( vel_core_error ** 2 + vel_wing_error ** 2 ):\n",
    "            flag = 4\n",
    "\n",
    "    final_results_3.update({key:[final_results_2[key][0], flag]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wing_vel_dis_list = []\n",
    "\n",
    "for key in final_results_3:\n",
    "    flag = final_results_3[key][1]\n",
    "    \n",
    "    if flag == 2 or flag ==3:\n",
    "        \n",
    "        model = final_results_3[key][0][0:8]\n",
    "        core_wing = wing_check(model)\n",
    "        wing_vel_dis = core_wing[1][2]\n",
    "\n",
    "        wing_vel_dis_list.append(wing_vel_dis)\n",
    "\n",
    "wing_vel_dis_array = np.array(wing_vel_dis_list)\n",
    "\n",
    "plt.hist(wing_vel_dis_array, bins = 14)\n",
    "\n",
    "plt.xlabel(r'Wing velocity dispersion (km s$^{-1}$)')\n",
    "plt.ylabel('Counts')\n",
    "\n",
    "# plt.savefig('zbin1_wingveldis_hist.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_gauss_params(wave, fluxden, k): #(wavelength array, fluxden array, k = 1 + z)\n",
    "    amp_OIII = amp_gauss(wave, fluxden)\n",
    "    \n",
    "    amp = 11 * amp_OIII / 12\n",
    "    z = k - 1\n",
    "    v = z * 300000\n",
    "    vel_sigma = 141\n",
    "    \n",
    "    ####################\n",
    "\n",
    "    m = (fluxden[-1] - fluxden[0]) / (wave[-1] - wave[0])\n",
    "    b = (m * -wave[0]) + fluxden[0]\n",
    "    \n",
    "    return [amp, v, vel_sigma, m, b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete: 130 \n",
      "Runtime: 24.796875s\n"
     ]
    }
   ],
   "source": [
    "############################### here is the run to refit all the single gaussians\n",
    "###############################\n",
    "\n",
    "\n",
    "# preset_parameters_single = {} #called with spec-XXXX-XXXXX-XXXX, PLATE-MJD-FIBERID, fit\n",
    "TRIALS = 100 #set number of trials for the Monte-Carlo error\n",
    "# MC_flags = np.zeros((TRIALS, len(trimmed_specs)))\n",
    "count = 0\n",
    "\n",
    "start_time = time.process_time()\n",
    "# negative_amp_fits = []\n",
    "\n",
    "for key in final_results_3: #loop and use the fit on all the trimmed specs\n",
    "    \n",
    "    flag = final_results_3[key][1]\n",
    "    \n",
    "    if flag == 1:\n",
    "\n",
    "        OIII_wave    = trimmed_specs[key][0] #array with wavelength values for the current spectrum in angstrom\n",
    "        OIII_fluxden = trimmed_specs[key][1] #array with corresponding flux density values\n",
    "        k            = trimmed_specs[key][2] #corresponding z + 1 value\n",
    "        OIII_error   = trimmed_specs[key][3] #array with corresponding flux density error values\n",
    "        \n",
    "        OIII_wave    = np.float64(OIII_wave)\n",
    "        OIII_fluxden = np.float64(OIII_fluxden)\n",
    "        OIII_error   = np.float64(OIII_error)\n",
    "        \n",
    "        MC_params = np.zeros((TRIALS, 6))\n",
    "\n",
    "        ###############################\n",
    "        ###############################ERROR IN PARAMETERS\n",
    "        \n",
    "        single_gaussian_parameters = single_gauss_params(OIII_wave, OIII_fluxden, k)\n",
    "        \n",
    "        results = []\n",
    "\n",
    "        for r in range(TRIALS): #create a fit for every row of MC_params, number of TRIALS\n",
    "            iter_dat = np.random.normal(OIII_fluxden, OIII_error) #fluctuate the data using the given error\n",
    "            iter_dat = iter_dat.astype('float64') #change data type so it works lol\n",
    "\n",
    "            fit_params = leastsq(single_gaussian_lincont_fit, x0 = single_gaussian_parameters, args = (OIII_wave, iter_dat, OIII_error), maxfev = 100000) #call the least squares fit using which ever initial conditions were used\n",
    "            params = fit_params[0] #take only the parameters\n",
    "            \n",
    "            MC_params[r][0:5] = params #set the first 5 columns with the parameters\n",
    "            \n",
    "        for i in range(5): #now loop over the first 8 columns\n",
    "            results.append(np.median(MC_params[:,i]))\n",
    "            results.append(np.std(MC_params[:,i]))\n",
    "\n",
    "        pre_final_params = np.array(results)\n",
    "        \n",
    "        final_params = np.zeros(16)\n",
    "\n",
    "        ###############################\n",
    "        ###############################\n",
    "        \n",
    "        fit_params = leastsq(single_gaussian_lincont_fit, x0 = single_gaussian_parameters, args = (OIII_wave, OIII_fluxden, OIII_error), maxfev = 100000) #call the least squares fit using which ever initial conditions were used\n",
    "        params = fit_params[0] #take only the parameters\n",
    "\n",
    "        ###############################\n",
    "        ###############################\n",
    "        \n",
    "        final_params[0:3]   = pre_final_params[0:6][0::2]\n",
    "        final_params[6:8]   = pre_final_params[6:10][0::2]\n",
    "\n",
    "        final_params[8:11]  = pre_final_params[0:6][1::2]\n",
    "        final_params[14:16] = pre_final_params[6:10][1::2]\n",
    "        \n",
    "        final_results_3.update({key:[final_params, flag]})\n",
    "        \n",
    "        count += 1\n",
    "        print(\"\\r\" + \"Complete: {}\".format(count), end = \"\")\n",
    "        \n",
    "print(\" \")\n",
    "print(\"Runtime: {}s\".format((time.process_time() - start_time)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############RUN CELLS UP TO HERE FOR LATEST RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 130, 2: 115, 3: 40, 4: 20}\n"
     ]
    }
   ],
   "source": [
    "flags = []\n",
    "for key in final_results_3:\n",
    "    flag = final_results_3[key][1]\n",
    "    flags.append(flag)\n",
    "flags = np.array(flags) #convert the list into an array for faster processing\n",
    "unique, counts = np.unique(flags, return_counts=True) #count occurences of each flag\n",
    "classifications = dict(zip(unique, counts)) #put into dictionary\n",
    "print(classifications) #print the dictionary to view the wing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outflow Percentages z bin 1\n",
      "\n",
      "\n",
      "NoOutflowMean: 49.18\n",
      "\n",
      "\n",
      "BlueWingMean: 37.70\n",
      "\n",
      "\n",
      "RedWingMean: 13.11\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    bad_data_mean   = (100 * classifications[0]) / len(final_results_3)\n",
    "\n",
    "    no_outflow_mean = (100 * ( classifications[1] + classifications[4]) ) / len(final_results_3)\n",
    "\n",
    "    blu_wing_mean   = (100 * classifications[2]) / len(final_results_3)\n",
    "\n",
    "    red_wing_mean   = (100 * classifications[3]) / len(final_results_3)\n",
    "    \n",
    "    print('Outflow Percentages z bin 1')\n",
    "    print('\\n')\n",
    "\n",
    "    print('BadDataMean: {:.2f}'.format(bad_data_mean))\n",
    "    # print('BadDataErr: {:.2f}'.format(bad_data_std))\n",
    "    print('\\n')\n",
    "\n",
    "    print('NoOutflowMean: {:.2f}'.format(no_outflow_mean))\n",
    "    # print('NoOutflowErr: {:.2f}'.format(no_outflow_std))\n",
    "    print('\\n')\n",
    "\n",
    "    print('BlueWingMean: {:.2f}'.format(blu_wing_mean))\n",
    "    # print('BlueWingErr: {:.2f}'.format(blu_wing_std))\n",
    "    print('\\n')\n",
    "\n",
    "    print('RedWingMean: {:.2f}'.format(red_wing_mean))\n",
    "    # print('RedWingErr: {:.2f}'.format(red_wind_std))\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "except:\n",
    "    no_outflow_mean = (100 * ( classifications[1] + classifications[4]) ) / len(final_results_3)\n",
    "\n",
    "    blu_wing_mean   = (100 * classifications[2]) / len(final_results_3)\n",
    "\n",
    "    red_wing_mean   = (100 * classifications[3]) / len(final_results_3)\n",
    "    \n",
    "    print('Outflow Percentages z bin 1')\n",
    "    print('\\n')\n",
    "\n",
    "    print('NoOutflowMean: {:.2f}'.format(no_outflow_mean))\n",
    "    # print('NoOutflowErr: {:.2f}'.format(no_outflow_std))\n",
    "    print('\\n')\n",
    "\n",
    "    print('BlueWingMean: {:.2f}'.format(blu_wing_mean))\n",
    "    # print('BlueWingErr: {:.2f}'.format(blu_wing_std))\n",
    "    print('\\n')\n",
    "\n",
    "    print('RedWingMean: {:.2f}'.format(red_wing_mean))\n",
    "    # print('RedWingErr: {:.2f}'.format(red_wind_std))\n",
    "    print('\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate vel_shift = v_wing - v_core\n",
    "final_results_4 = {}\n",
    "\n",
    "for key in final_results_3:\n",
    "    model_error = final_results_3[key][0]\n",
    "    model = final_results_3[key][0][0:8]\n",
    "    flag = final_results_3[key][1]\n",
    "    \n",
    "    if flag == 2 or flag == 3 or flag == 4:\n",
    "        \n",
    "        core_wing = wing_check(model)\n",
    "\n",
    "        core = core_wing[0]\n",
    "        wing = core_wing[1]\n",
    "\n",
    "        vel_core = core[1]\n",
    "        vel_wing = wing[1]\n",
    "\n",
    "        vel_shift = vel_wing - vel_core\n",
    "    \n",
    "    else:\n",
    "        vel_shift = 0\n",
    "    \n",
    "    final_final_params = [model_error, vel_shift, flag]\n",
    "    \n",
    "    final_results_4.update({key:final_final_params})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = []\n",
    "\n",
    "##############################################################\n",
    "\n",
    "array_core_amp        = []\n",
    "array_core_amp_err    = []\n",
    "\n",
    "array_core_vel        = []\n",
    "array_core_vel_err    = []\n",
    "\n",
    "array_core_veldis     = []\n",
    "array_core_veldis_err = []\n",
    "\n",
    "##############################################################\n",
    "\n",
    "array_wing_amp        = []\n",
    "array_wing_amp_err    = []\n",
    "\n",
    "array_wing_vel        = []\n",
    "array_wing_vel_err    = []\n",
    "\n",
    "array_wing_veldis     = []\n",
    "array_wing_veldis_err = []\n",
    "\n",
    "##############################################################\n",
    "\n",
    "array_vel_shifts      = []\n",
    "array_vel_shifts_err  = []\n",
    "\n",
    "##############################################################\n",
    "\n",
    "flags           = []\n",
    "\n",
    "##############################################################\n",
    "\n",
    "for key in final_results_4:\n",
    "    keys.append(key)\n",
    "    \n",
    "    params_err = final_results_4[key][0]\n",
    "    \n",
    "    parameters = params_err[0:8]\n",
    "    \n",
    "    core_wing = wing_check(parameters)\n",
    "    \n",
    "    core = core_wing[0]\n",
    "    wing = core_wing[1]\n",
    "    \n",
    "    vel_shift = final_results_4[key][1]\n",
    "    flag = final_results_4[key][2]\n",
    "    \n",
    "    if core[0] == params_err[0:3][0] and core[1] == params_err[0:3][1] and core[2] == params_err[0:3][2]:\n",
    "        core_amp        = core[0]\n",
    "        core_vel        = core[1]\n",
    "        core_veldis     = core[2]\n",
    "        \n",
    "        core_amp_err    = params_err[8]\n",
    "        core_vel_err    = params_err[9]\n",
    "        core_veldis_err = params_err[10]\n",
    "        \n",
    "        ##############################################################\n",
    "    \n",
    "        wing_amp        = wing[0]\n",
    "        wing_vel        = wing[1]\n",
    "        wing_veldis     = wing[2]\n",
    "        \n",
    "        wing_amp_err    = params_err[11]\n",
    "        wing_vel_err    = params_err[12]\n",
    "        wing_veldis_err = params_err[13]\n",
    "    \n",
    "    elif core[0] == params_err[3:6][0] and core[1] == params_err[3:6][1] and core[2] == params_err[3:6][2]:\n",
    "        core_amp        = core[0]\n",
    "        core_vel        = core[1]\n",
    "        core_veldis     = core[2]\n",
    "        \n",
    "        core_amp_err    = params_err[11]\n",
    "        core_vel_err    = params_err[12]\n",
    "        core_veldis_err = params_err[13]\n",
    "        \n",
    "        ##############################################################\n",
    "    \n",
    "        wing_amp        = wing[0]\n",
    "        wing_vel        = wing[1]\n",
    "        wing_veldis     = wing[2]\n",
    "        \n",
    "        wing_amp_err    = params_err[8]\n",
    "        wing_vel_err    = params_err[9]\n",
    "        wing_veldis_err = params_err[10]\n",
    "    \n",
    "    ##############################################################\n",
    "\n",
    "    array_core_amp.append(core_amp)\n",
    "    array_core_amp_err.append(core_amp_err)\n",
    "\n",
    "    array_core_vel.append(core_vel)\n",
    "    array_core_vel_err.append(core_vel_err)\n",
    "    \n",
    "    array_core_veldis.append(core_veldis)\n",
    "    array_core_veldis_err.append(core_veldis_err)\n",
    "\n",
    "    ##############################################################\n",
    "\n",
    "    array_wing_amp.append(wing_amp)\n",
    "    array_wing_amp_err.append(wing_amp_err)\n",
    "\n",
    "    array_wing_vel.append(wing_vel)\n",
    "    array_wing_vel_err.append(wing_vel_err)\n",
    "    \n",
    "    array_wing_veldis.append(wing_veldis)\n",
    "    array_wing_veldis_err.append(wing_veldis_err)\n",
    "\n",
    "    ##############################################################\n",
    "\n",
    "    array_vel_shifts.append(vel_shift)\n",
    "    \n",
    "    if flag == 2 or flag == 3 or flag == 4:\n",
    "        vel_shift_err = np.sqrt( wing_vel_err ** 2 + core_vel_err ** 2 )\n",
    "    \n",
    "    if flag == 0 or flag == 1:\n",
    "        vel_shift_err = 0\n",
    "        \n",
    "    array_vel_shifts_err.append(vel_shift_err)\n",
    "\n",
    "    ##############################################################\n",
    "    \n",
    "    flags.append(flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys = np.chararray(key)\n",
    "\n",
    "##############################################################\n",
    "\n",
    "array_core_amp        = np.array(array_core_amp)\n",
    "array_core_amp_err    = np.array(array_core_amp_err)\n",
    "\n",
    "array_core_vel        = np.array(array_core_vel)\n",
    "array_core_vel_err    = np.array(array_core_vel_err)\n",
    "\n",
    "array_core_veldis     = np.array(array_core_veldis)\n",
    "array_core_veldis_err = np.array(array_core_veldis_err)\n",
    "\n",
    "##############################################################\n",
    "\n",
    "array_wing_amp        = np.array(array_wing_amp)\n",
    "array_wing_amp_err    = np.array(array_wing_amp_err)\n",
    "\n",
    "array_wing_vel        = np.array(array_wing_vel)\n",
    "array_wing_vel_err    = np.array(array_wing_vel_err)\n",
    "\n",
    "array_wing_veldis     = np.array(array_wing_veldis)\n",
    "array_wing_veldis_err = np.array(array_wing_veldis_err)\n",
    "\n",
    "##############################################################\n",
    "\n",
    "array_vel_shifts      = np.array(array_vel_shifts)\n",
    "array_vel_shifts_err  = np.array(array_vel_shifts_err)\n",
    "\n",
    "##############################################################\n",
    "\n",
    "flags           = np.array(flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################SET UP FITS TABLE\n",
    "###############################\n",
    "\n",
    "col0 = fits.Column(name = 'KEY', format = '20A', array = keys)\n",
    "\n",
    "col1 = fits.Column(name = 'CORE_AMP', format = 'D', array = array_core_amp)\n",
    "col2 = fits.Column(name = 'CORE_AMP_ERR', format = 'D', array = array_core_amp_err)\n",
    "\n",
    "col3 = fits.Column(name = 'CORE_VEL', format = 'D', array = array_core_vel)\n",
    "col4 = fits.Column(name = 'CORE_VEL_ERR', format = 'D', array = array_core_vel_err)\n",
    "\n",
    "col5 = fits.Column(name = 'CORE_VELDIS', format = 'D', array = array_core_veldis)\n",
    "col6 = fits.Column(name = 'CORE_VELDIS_ERR', format = 'D', array = array_core_veldis_err)\n",
    "\n",
    "###############################\n",
    "###############################\n",
    "\n",
    "col7 = fits.Column(name = 'WING_AMP', format = 'D', array = array_wing_amp)\n",
    "col8 = fits.Column(name = 'WING_AMP_ERR', format = 'D', array = array_wing_amp_err)\n",
    "\n",
    "col9 = fits.Column(name = 'WING_VEL', format = 'D', array = array_wing_vel)\n",
    "col10 = fits.Column(name = 'WING_VEL_ERR', format = 'D', array = array_wing_vel_err)\n",
    "\n",
    "col11 = fits.Column(name = 'WING_VELDIS', format = 'D', array = array_wing_veldis)\n",
    "col12 = fits.Column(name = 'WING_VELDIS_ERR', format = 'D', array = array_wing_veldis_err)\n",
    "\n",
    "###############################\n",
    "###############################\n",
    "\n",
    "col13 = fits.Column(name = 'VELSHIFT', format = 'D', array = array_vel_shifts)\n",
    "col14 = fits.Column(name = 'VELSHIFT_ERR', format = 'D', array = array_vel_shifts_err)\n",
    "\n",
    "###############################\n",
    "###############################\n",
    "\n",
    "col15 = fits.Column(name = 'FLAG', format = 'I', array = flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldefs = fits.ColDefs([col0, col1, col2, col3, col4, col5, col6, col7, col8, col9, col10, col11, col12, col13, col14, col15])\n",
    "hdu = fits.BinTableHDU.from_columns(coldefs)\n",
    "\n",
    "zbin4_results = Table(hdu.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zbin4_results.write('woo_zbin4_results.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_scale = []\n",
    "for key in trimmed_specs:\n",
    "    fd = trimmed_specs[key][4]\n",
    "    fd_scale.append(fd)\n",
    "\n",
    "fd_scale = np.array(fd_scale)\n",
    "\n",
    "hdul = fits.open('woo_results_files/woo_zbin4_results.fits')\n",
    "data = hdul[1].data\n",
    "zbin4_cols = data.columns\n",
    "hdul.close()\n",
    "new_col = fits.ColDefs([fits.Column(name='FLUXDEN_SCALE', format='D', array = fd_scale)])\n",
    "\n",
    "new_hdu = fits.BinTableHDU.from_columns(zbin4_cols + new_col)\n",
    "Table(new_hdu.data).write('woo_zbin4_results_v2.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
